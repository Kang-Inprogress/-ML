{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "혼공ML 8챕터: 신경망(이미지 처리)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqqqsgWJ+lUoutfQfSAcSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kang-Inprogress/-ML/blob/main/%ED%98%BC%EA%B3%B5ML_8%EC%B1%95%ED%84%B0_%EC%8B%A0%EA%B2%BD%EB%A7%9D(%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%B2%98%EB%A6%AC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGibcJF4kaY0"
      },
      "source": [
        "# **Convolution Neural Network**\n",
        "\n",
        "CNN에서...\n",
        "\n",
        "뉴런 = 필터: 필터처럼 몇 개의 입력만을 가지고 출력을 하나 만들어낸다\n",
        "\n",
        "필터의 크기 또한 우리가 지정해야 할 하이퍼파라미터이다.\n",
        "\n",
        "합성곱 계산을 통해 얻은 출력을 특성 맵feature map 이라고 한다.\n",
        "\n",
        "합성곱 층에 있는 필터(뉴런)의 가중치가 모두 다르기 때문에 특성 맵을 필터 개수만큼 쌓은 차원의 출력이 된다. 특성 맵(2차원) x 필터 개수 => 3차원\n",
        "\n",
        "출력(특성 맵)이 2차원 형태를 유지하기 때문에:데이터의 공간 특성을 그대로 유지하며 학습하기 때문에 *이미지* 처리 분야에서 뛰어난 성능을 발휘한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeNcIOLmoU45"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "keras.layers.conv2D(10, kernel_size(3,3), activation=\"relu\") # kernel_size 는 보통 (3,3) 이나 (5,5)가 권장된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JUFbGBnosD8"
      },
      "source": [
        "# 패딩과 스트라이드\n",
        "\n",
        "(4,4) 크기의 입력을 (3,3)크기의 커널로 합성곱을 했을 때 똑같은 크기의 차원으로 출력으로 하려한다면, 입력을 (6,6)이라고 속이면 될 것이다. 원래 (4,4)만큼의 데이터를 놔두고 나머지를 0값으로 채워 (6,6)을 만드는 기법을 **패딩**이라고 한다.\n",
        "\n",
        "-> 0으로 채우는데 출력값에 영향을 주지 않는가? 간단히 말하자면 패딩의 역할은 순전히 커널의 합성곱 횟수를 늘려주는 것밖에는 없다. 실제계산에서 0이면 영향이 미치는 일이 없기 때문이다.\n",
        "\n",
        "+ 0으로 채우는 것을 세임 패딩(same padding). \n",
        "+ 순수한 입력 배열에서 합성곱을 하여 특성 맵을 만드는 경우를 밸리드 패딩valid padding이라고 한다.\n",
        "\n",
        "-> 세임 패딩을 하는 이유? 밸리드 패딩을 사용한다면 자연스레 중간에 있는 값들은 중앙에 있는 커널들과 비교했을 때 참여비율이 차이가 난다. 중요도가 떨어져보이게 되기 때문\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0GwsK_oqo-q"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "keras.layers.conv2D(10, kernel_size(3,3), activation=\"relu\", padding=\"same\") # padding을 부여 하지 않으면 자동으로 밸리드 패딩이 된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67u01Kddr4Og"
      },
      "source": [
        "합성곱을 할 때 커널은 한 칸씩 이동했는데 이 경우 **스트라이드**가 1이다. 스트라이드는 strides 속성으로 움직일 칸 수를 직접 조절할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4quLO0OyA-J"
      },
      "source": [
        "# 풀링 Pooling\n",
        "합성곱 처럼 입력 위를 지나가면서 수행한다. 풀링에는 가중치가 없기 때문에 최대값이나 평균값을 계산해서 크기를 작게 설정한다.\n",
        "(n, n) 크기의 풀링에서...\n",
        "\n",
        "+ 최대 풀링: 해당 차원의 원소에서 가장 큰 값을 출력\n",
        "\n",
        "+ 평균 풀링: 해당 차원의 원소들의 평균 값을 출력\n",
        "\n",
        "이동 시 합성곱의 필터와 다른 점은 겹치지 않게 이동한다는 점이다: 풀링 크기 = 스트라이드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBxcQN-lyxAk"
      },
      "source": [
        "keras.layers.MaxPooling2D(2)\n",
        "\n",
        "keras.layers.MaxPooling2D(2, strides=2, padding=\"valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i3cBg1yzY5e"
      },
      "source": [
        "**입력 차원이 3차원 이상이라면 필터 또한 그 차원과 해당 차원의 깊이가 같아야한다. 보통 합성곱 층은 3차원을 기대**\n",
        "\n",
        "필터의 차원이 몇 개이던지 출력은 항상 하나의 값이다.\n",
        "3차원 입력에서, 필터하나는 1층의 특성 맵을 출력하니까 필터가 n개면 특성 맵의 층도 n개로 이루어 질 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9I7GqLg7PJ-"
      },
      "source": [
        "# 실전: 합성곱 신경망을 사용한 이미지 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYR4Q0YX7TAj"
      },
      "source": [
        "CNN에서 입력 이미지는 항상 깊이(채널)이 있어야한다. 그러므로 최소 1의 깊이(채널)차원을 추가해 준다.\n",
        "\n",
        "MNIST 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZouRSF173j2",
        "outputId": "ac044790-b5d5-4f29-ea40-7cb6ea5e412b"
      },
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input.reshape(-1, 28, 28, 1)/ 255.0 # reshape(-1, 28, 28, 1)로 깊이가 1인 차원을 추가했다\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWbpzGbZ8txm"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1))) # 필터(뉴런) 32개, 커널 사이즈(3,3), 활성화함수=\"relu\", 세임패딩\n",
        "model.add(keras.layers.MaxPooling2D(2)) # (2, 2)풀링으로 절반으로 줄어듦\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5emPFnZ-K-z"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjon-BwW-lpg"
      },
      "source": [
        "keras.utils.plot_model(model, show_shapes=True, to_file=\"cnn-architecture.png\", dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGaU_ODU_kpI",
        "outputId": "b8c31755-969a-4840-af55-10fa2dd08793"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best-cnn-model.h5\")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
        "history = model.fit(train_scaled, train_target, epochs=20, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 36s 3ms/step - loss: 0.5412 - accuracy: 0.8062 - val_loss: 0.3526 - val_accuracy: 0.8692\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3609 - accuracy: 0.8680 - val_loss: 0.3071 - val_accuracy: 0.8861\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3137 - accuracy: 0.8867 - val_loss: 0.2878 - val_accuracy: 0.8881\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2804 - accuracy: 0.8986 - val_loss: 0.2528 - val_accuracy: 0.9037\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2570 - accuracy: 0.9059 - val_loss: 0.2393 - val_accuracy: 0.9114\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2374 - accuracy: 0.9127 - val_loss: 0.2275 - val_accuracy: 0.9147\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2224 - accuracy: 0.9182 - val_loss: 0.2304 - val_accuracy: 0.9131\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2068 - accuracy: 0.9236 - val_loss: 0.2255 - val_accuracy: 0.9190\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2011 - accuracy: 0.9252 - val_loss: 0.2247 - val_accuracy: 0.9196\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1859 - accuracy: 0.9311 - val_loss: 0.2287 - val_accuracy: 0.9183\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1750 - accuracy: 0.9345 - val_loss: 0.2295 - val_accuracy: 0.9185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dPDpskvuhQq",
        "outputId": "3fb34258-46dd-4176-a8c9-8deed6b05997"
      },
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23247025907039642, 0.9190000295639038]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqznaW4WuypW",
        "outputId": "ed38450f-7174-4215-b9e5-81bccee45d2d"
      },
      "source": [
        "preds = model.predict(val_scaled[0:1]) # (1, 28, 28, 1) 크기의 데이터 전달\n",
        "print(preds)  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.0977413e-20 1.4621292e-31 7.2727220e-23 2.5093261e-21 4.7217259e-21\n",
            "  9.6351951e-23 7.0386224e-22 5.2295823e-22 1.0000000e+00 3.5005407e-24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMcLSia3ySEX"
      },
      "source": [
        "# CNN 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkWmRhK6ypZ7"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model(\"best-cnn-model.h5\")\n",
        "# model.layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6-QFxcfyvXH",
        "outputId": "ef6b6949-8e26-4843-8ec8-267fcee6e188"
      },
      "source": [
        "conv = model.layers[0]\n",
        "print(\"가중치의 크기: \", conv.weights[0].shape, \"| 절편의 크기: \", conv.weights[1].shape) # weight는 파이썬 리스트. 첫 번째 원소: 가중치와 두 번째 원소: 절편의 크기를 알 수 있다.\n",
        "conv_weights = conv.weights[0].numpy()\n",
        "print(\"가중치의 평균값:\", conv_weights.mean(), \"| 가중치의 표준편차: \", conv_weights.std())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "가중치의 크기:  (3, 3, 1, 32) | 절편의 크기:  (32,)\n",
            "가중치의 평균값: -0.020119244 | 가중치의 표준편차:  0.27198008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njl3szxR_aF2"
      },
      "source": [
        "**시각화해서 훈련된 모델의 가중치와 그렇지 않은 모델의 가중치를 비교하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "GHDIvhM_-pW8",
        "outputId": "5f788381-3dea-4dd0-cea8-a9377da6aa20"
      },
      "source": [
        "# 눈으로 가중치 확인하기\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(2, 16, figsize=(15,2))\n",
        "for i in range(2):\n",
        "  for j in range(16):\n",
        "    axs[i, j].imshow(conv_weights[:, :, 0, i*16 + j], vmin=-0.5, vmax=0.5) # conv_weights의 [:, :, :0, 0]부터 [:, :, :0, 31]까지의 커널 출력\n",
        "    axs[i, j].axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 결과값에서 밝은 부분이 가중치가 높은 것이다."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x144 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVjmeOa-_heo",
        "outputId": "1fb4dab9-3dbc-4830-82c2-6c198896f44f"
      },
      "source": [
        "# 입력이 같은 모델 생성(훈련되지않음)\n",
        "no_training_model = keras.Sequential()\n",
        "no_training_model.add(keras.layers.Conv2D(32, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)))\n",
        "# no_training_conv = no_training_model.layers[0]\n",
        "# print(no_training_conv.weights[0].shape)\n",
        "no_training_weights = no_training_conv.weights[0].numpy()\n",
        "print(no_training_weights.mean(), no_training_weights.std())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0009956631 0.08363045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "UHzvNlqOBkSG",
        "outputId": "b881ca2a-b92c-43cd-c21f-686e8ed9ce02"
      },
      "source": [
        "fig, axs = plt.subplots(2, 16, figsize=(15,2))\n",
        "for i in range(2):\n",
        "  for j in range(16):\n",
        "    axs[i, j].imshow(no_training_weights[:, :, 0, i*16 + j], vmin=-0.5, vmax=0.5)\n",
        "    axs[i, j].axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x144 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32WsV4-dCIFH"
      },
      "source": [
        "# 함수형 API로 다시 실습해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_7qOaGeFZSW"
      },
      "source": [
        "**밀집층을 재현해보기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hIieXqiCxXy",
        "outputId": "21fd10c1-91ad-4ca1-8743-1b5696ddf53d"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "dense1 = keras.layers.Dense(100, activation=\"sigmoid\")\n",
        "dense2 = keras.layers.Dense(100, activation=\"sigmoid\")\n",
        "dense3 = keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "inputs = keras.Input(shape=(784, ))\n",
        "\n",
        "# 변수 = 층(층의 입력)\n",
        "hidden = dense1(inputs)\n",
        "hidden2 = dense2(hidden)\n",
        "outputs = dense3(hidden2)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f93fd787250>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f93fd783990>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f93fd783ed0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f93fd783b50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Am2AO3oGEzP"
      },
      "source": [
        "model 객체의 입력과 Conv2D의 출력을 알 수 있다면, 이 둘을 연결하여 새로운 모델을 만드는 것도 가능하다!\n",
        "\n",
        "InputLayer - Conv2D - Maxpooling2D - Conv2D - Maxpooling2D - Flatten - Dense - Dropout - Dense 함수형 API로 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_8HNwQMFc1r"
      },
      "source": [
        "**특성 맵 시각화**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "yrwjlKkJFfed",
        "outputId": "f22b4dfe-3ec8-4725-cd2b-c6fb4b95b281"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "plt.imshow(train_input[0], cmap=\"gray_r\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}